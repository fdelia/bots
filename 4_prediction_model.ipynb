{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Prediction of User Reactions\n",
    "We want to predict:\n",
    "* How to get high score/consensus (upvotes - downvotes)\n",
    "* How to be controversial (upvotes + downvotes)  \n",
    "in the comments.\n",
    "\n",
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Not necessary, but I like the ggplot style better\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "df_art = pd.read_csv('articles_2017_09.csv')\n",
    "df_com = pd.read_csv('comments_2017_09.csv').sample(250000) # crop because battery life, skews data\n",
    "# Make float better readable\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "             tId  cId  mob  vup  vdo                      tit        aut  \\\n",
      "250203  10003016  1_1    1  602   30  die spitze des eisbergs  Mani Motz   \n",
      "250202  10003016  5_5    1  149   39                    fake?     Müller   \n",
      "250211  10003016  7_7    1  503   37              abscheulich      Pitri   \n",
      "\n",
      "                       time  \\\n",
      "250203  am 08.08.2017 07:34   \n",
      "250202  am 08.08.2017 07:38   \n",
      "250211  am 08.08.2017 07:39   \n",
      "\n",
      "                                                      con  time_since_epoch  \\\n",
      "250203               erschreckend was alles möglich ist.     1502177640.000   \n",
      "250202   im text wird erwähnt das black death angebote...    1502177880.000   \n",
      "250211   was sind das nur für kreaturen. sorry, ich ka...    1502177940.000   \n",
      "\n",
      "              ...         cat_people  cat_play  cat_playview  cat_schweiz  \\\n",
      "250203        ...                  0         0             0            0   \n",
      "250202        ...                  0         0             0            0   \n",
      "250211        ...                  0         0             0            0   \n",
      "\n",
      "        cat_sport  cat_wissen  header_len  text_len  text_num_words  \\\n",
      "250203          0           0          41      3429             509   \n",
      "250202          0           0          41      3429             509   \n",
      "250211          0           0          41      3429             509   \n",
      "\n",
      "        time_since_first  \n",
      "250203             0.000  \n",
      "250202             0.067  \n",
      "250211             0.083  \n",
      "\n",
      "[3 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_dt_obj(time):\n",
    "    time = time.replace('am ', '')\n",
    "    # Make datetime object from string\n",
    "    return datetime.strptime(time, '%d.%m.%Y %H:%M')\n",
    "\n",
    "def time_since_epoch(time):\n",
    "    return (get_dt_obj(time)-datetime(1970,1,1)).total_seconds()\n",
    "\n",
    "def get_hour_of_day(time):\n",
    "    return get_dt_obj(time).hour\n",
    "\n",
    "def get_weekday(time):\n",
    "    return get_dt_obj(time).weekday()\n",
    "\n",
    "# Basically same as \"the hour of week\" or \"weekday_hourOfDay\"\n",
    "def get_weekday_float(time):\n",
    "    hour = float(get_hour_of_day(time))\n",
    "    weekday = get_weekday(time)\n",
    "    return float(weekday) + hour / 24\n",
    "\n",
    "def get_weekday_hour(time):\n",
    "    return '{}_{}'.format(get_weekday(time), get_hour_of_day(time))\n",
    "\n",
    "df_com['time_since_epoch'] = df_com['time'].apply(time_since_epoch)\n",
    "df_com['hour'] = df_com['time'].apply(get_hour_of_day)\n",
    "df_com['weekday'] = df_com['time'].apply(get_weekday) # 0 = Monday\n",
    "df_com['weekday_fl'] = df_com['time'].apply(get_weekday_float)\n",
    "#df_com['weekday_hour'] = df_com['time'].apply(get_weekday_hour)\n",
    "df_com['is_answer'] = df_com['tit'].apply(lambda x: str(x).startswith('@'))\n",
    "df_com['con_len'] = df_com['con'].apply(lambda x: len(x))\n",
    "df_com['con_num_words'] = df_com['con'].apply(lambda x: len(x.split()))\n",
    "df_com['score'] = df_com['vup'] - df_com['vdo']\n",
    "df_com['contr'] = df_com['vup'] + df_com['vdo']\n",
    "\n",
    "df_com['tit'] = df_com['tit'].str.lower()\n",
    "df_com['con'] = df_com['con'].str.lower()\n",
    "\n",
    "def get_category(link):\n",
    "    t = link.split('/')\n",
    "    if len(t) <= 1:\n",
    "        return ''\n",
    "    else:\n",
    "        return t[1]\n",
    "\n",
    "df_art['cat'] = df_art['link'].apply(get_category)\n",
    "df_art['cat_copy'] = df_art['cat']\n",
    "df_art = pd.get_dummies(df_art, columns=['cat'])\n",
    "\n",
    "df_art['header_len'] = df_art['header'].apply(lambda x: len(x))\n",
    "df_art['text_len'] = df_art['text'].apply(lambda x: len(str(x)))\n",
    "df_art['text_num_words'] = df_art['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Left inner join\n",
    "df_merge = pd.merge(left=df_com, right=df_art, left_on='tId', right_on='tId')\n",
    "\n",
    "# is empty: (= all comments correspond to an article)\n",
    "print(len(df_merge[pd.isnull(df_merge['tit'])]))\n",
    "df_merge = df_merge[pd.notnull(df_merge['tit'])]\n",
    "\n",
    "# Get order of comments per article\n",
    "df_merge_art = df_merge.sort_values(['tId', 'time_since_epoch']).groupby('tId')\n",
    "# Get time since the first comment\n",
    "def get_time_since_first(group):\n",
    "    first = group.iloc[:1]['time_since_epoch']\n",
    "    group['time_since_first'] = group['time_since_epoch'].apply(lambda x: (x - first) / 3600)\n",
    "    # Remove those very late comments, after x hours\n",
    "    #group = group[group['time_since_first'] < 36]\n",
    "    return group\n",
    "\n",
    "df_merge_art = df_merge_art.apply(get_time_since_first)\n",
    "print(df_merge_art.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to remove skew\n",
    "__Rescaling__: Add or subtract a constant and then multiply or divide by a constant.  \n",
    "__Normalizing__: Dividing by a norm of the vector, e.g. make Euclidean length equal to one. Sometimes make all elements lie in [0, 1].  \n",
    "__Standardizing__: Subtracting a measure of location and dividing by a measure of scale. Eg. subtract the mean and divide by the std, thereby obtaining a standard normal distribution.\n",
    "\n",
    "These terms are sometimes used interchangeably.\n",
    "\n",
    "It's usually better to have the input values centered around zero, unless the output activation function has a range of [0, 1] (neural networks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_cat\n",
      "negative    82567\n",
      "small       95286\n",
      "big         76070\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>score_trans</th>\n",
       "      <th>vup</th>\n",
       "      <th>vdo</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday_fl</th>\n",
       "      <th>con_len_trans</th>\n",
       "      <th>text_len_trans</th>\n",
       "      <th>con_num_words_trans</th>\n",
       "      <th>text_num_words_trans</th>\n",
       "      <th>time_since_first_trans</th>\n",
       "      <th>header_len_trans</th>\n",
       "      <th>cat_schweiz</th>\n",
       "      <th>cat_finance</th>\n",
       "      <th>cat_sport</th>\n",
       "      <th>cat_wissen</th>\n",
       "      <th>cat_ausland</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_trans</th>\n",
       "      <td>0.477</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.352</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vup</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.352</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.329</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vdo</th>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>0.329</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.993</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.094</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday_fl</th>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.130</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>con_len_trans</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_len_trans</th>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.069</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.994</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>con_num_words_trans</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.067</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_num_words_trans</th>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.066</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_since_first_trans</th>\n",
       "      <td>-0.178</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>0.094</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>header_len_trans</th>\n",
       "      <td>0.022</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_schweiz</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.183</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.093</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>-0.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_finance</th>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_sport</th>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_wissen</th>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat_ausland</th>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        score  score_trans    vup    vdo  weekday   hour  \\\n",
       "score                   1.000        0.477  0.951  0.022   -0.005 -0.004   \n",
       "score_trans             0.477        1.000  0.352 -0.321   -0.004 -0.008   \n",
       "vup                     0.951        0.352  1.000  0.329   -0.000 -0.000   \n",
       "vdo                     0.022       -0.321  0.329  1.000    0.013  0.013   \n",
       "weekday                -0.005       -0.004 -0.000  0.013    1.000  0.010   \n",
       "hour                   -0.004       -0.008 -0.000  0.013    0.010  1.000   \n",
       "weekday_fl             -0.005       -0.005 -0.000  0.015    0.993  0.130   \n",
       "con_len_trans           0.011        0.034  0.018  0.024   -0.004 -0.049   \n",
       "text_len_trans          0.005       -0.003  0.007  0.008   -0.028 -0.042   \n",
       "con_num_words_trans     0.009        0.030  0.015  0.023   -0.005 -0.048   \n",
       "text_num_words_trans    0.006       -0.002  0.008  0.009   -0.036 -0.043   \n",
       "time_since_first_trans -0.178       -0.175 -0.219 -0.164    0.094 -0.072   \n",
       "header_len_trans        0.022        0.017  0.024  0.010   -0.035  0.014   \n",
       "cat_schweiz             0.035        0.022  0.043  0.031   -0.020 -0.040   \n",
       "cat_finance            -0.030       -0.013 -0.044 -0.051   -0.018 -0.017   \n",
       "cat_sport              -0.023       -0.035 -0.017  0.014    0.017  0.018   \n",
       "cat_wissen             -0.016       -0.008 -0.021 -0.021    0.023  0.037   \n",
       "cat_ausland             0.004       -0.007  0.017  0.042   -0.019  0.006   \n",
       "\n",
       "                        weekday_fl  con_len_trans  text_len_trans  \\\n",
       "score                       -0.005          0.011           0.005   \n",
       "score_trans                 -0.005          0.034          -0.003   \n",
       "vup                         -0.000          0.018           0.007   \n",
       "vdo                          0.015          0.024           0.008   \n",
       "weekday                      0.993         -0.004          -0.028   \n",
       "hour                         0.130         -0.049          -0.042   \n",
       "weekday_fl                   1.000         -0.010          -0.033   \n",
       "con_len_trans               -0.010          1.000           0.069   \n",
       "text_len_trans              -0.033          0.069           1.000   \n",
       "con_num_words_trans         -0.011          0.989           0.067   \n",
       "text_num_words_trans        -0.041          0.067           0.994   \n",
       "time_since_first_trans       0.084          0.040          -0.055   \n",
       "header_len_trans            -0.033          0.020           0.068   \n",
       "cat_schweiz                 -0.024          0.049           0.181   \n",
       "cat_finance                 -0.020          0.033           0.054   \n",
       "cat_sport                    0.019         -0.052          -0.012   \n",
       "cat_wissen                   0.027         -0.008          -0.015   \n",
       "cat_ausland                 -0.018          0.016           0.073   \n",
       "\n",
       "                        con_num_words_trans  text_num_words_trans  \\\n",
       "score                                 0.009                 0.006   \n",
       "score_trans                           0.030                -0.002   \n",
       "vup                                   0.015                 0.008   \n",
       "vdo                                   0.023                 0.009   \n",
       "weekday                              -0.005                -0.036   \n",
       "hour                                 -0.048                -0.043   \n",
       "weekday_fl                           -0.011                -0.041   \n",
       "con_len_trans                         0.989                 0.067   \n",
       "text_len_trans                        0.067                 0.994   \n",
       "con_num_words_trans                   1.000                 0.066   \n",
       "text_num_words_trans                  0.066                 1.000   \n",
       "time_since_first_trans                0.041                -0.057   \n",
       "header_len_trans                      0.018                 0.073   \n",
       "cat_schweiz                           0.044                 0.183   \n",
       "cat_finance                           0.031                 0.041   \n",
       "cat_sport                            -0.047                -0.002   \n",
       "cat_wissen                           -0.009                -0.017   \n",
       "cat_ausland                           0.013                 0.064   \n",
       "\n",
       "                        time_since_first_trans  header_len_trans  cat_schweiz  \\\n",
       "score                                   -0.178             0.022        0.035   \n",
       "score_trans                             -0.175             0.017        0.022   \n",
       "vup                                     -0.219             0.024        0.043   \n",
       "vdo                                     -0.164             0.010        0.031   \n",
       "weekday                                  0.094            -0.035       -0.020   \n",
       "hour                                    -0.072             0.014       -0.040   \n",
       "weekday_fl                               0.084            -0.033       -0.024   \n",
       "con_len_trans                            0.040             0.020        0.049   \n",
       "text_len_trans                          -0.055             0.068        0.181   \n",
       "con_num_words_trans                      0.041             0.018        0.044   \n",
       "text_num_words_trans                    -0.057             0.073        0.183   \n",
       "time_since_first_trans                   1.000            -0.030       -0.104   \n",
       "header_len_trans                        -0.030             1.000        0.093   \n",
       "cat_schweiz                             -0.104             0.093        1.000   \n",
       "cat_finance                              0.023             0.013       -0.407   \n",
       "cat_sport                                0.015            -0.156       -0.249   \n",
       "cat_wissen                               0.021             0.020       -0.246   \n",
       "cat_ausland                              0.017             0.003       -0.228   \n",
       "\n",
       "                        cat_finance  cat_sport  cat_wissen  cat_ausland  \n",
       "score                        -0.030     -0.023      -0.016        0.004  \n",
       "score_trans                  -0.013     -0.035      -0.008       -0.007  \n",
       "vup                          -0.044     -0.017      -0.021        0.017  \n",
       "vdo                          -0.051      0.014      -0.021        0.042  \n",
       "weekday                      -0.018      0.017       0.023       -0.019  \n",
       "hour                         -0.017      0.018       0.037        0.006  \n",
       "weekday_fl                   -0.020      0.019       0.027       -0.018  \n",
       "con_len_trans                 0.033     -0.052      -0.008        0.016  \n",
       "text_len_trans                0.054     -0.012      -0.015        0.073  \n",
       "con_num_words_trans           0.031     -0.047      -0.009        0.013  \n",
       "text_num_words_trans          0.041     -0.002      -0.017        0.064  \n",
       "time_since_first_trans        0.023      0.015       0.021        0.017  \n",
       "header_len_trans              0.013     -0.156       0.020        0.003  \n",
       "cat_schweiz                  -0.407     -0.249      -0.246       -0.228  \n",
       "cat_finance                   1.000     -0.124      -0.123       -0.114  \n",
       "cat_sport                    -0.124      1.000      -0.075       -0.070  \n",
       "cat_wissen                   -0.123     -0.075       1.000       -0.069  \n",
       "cat_ausland                  -0.114     -0.070      -0.069        1.000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def show_hist(col):\n",
    "    df_merge_art['bins'] = pd.cut(df_merge_art[col], 100)\n",
    "    h = df_merge_art.groupby(['bins']).size().plot.bar(title=col)\n",
    "    plt.gca().get_xaxis().set_visible(False)\n",
    "    plt.show()\n",
    "    \n",
    "# This categories are defined randomly\n",
    "bins = [-np.inf, 2, 25, np.inf]\n",
    "labels = ['negative', 'small', 'big']\n",
    "df_merge_art['score_cat'] = pd.cut(df_merge_art['score'], bins, labels=labels)\n",
    "print(df_merge_art.groupby('score_cat').size())\n",
    "\n",
    "# This doesn't change anything, which is interesting\n",
    "#df = df[(df['score']<2) | (df['score']>=25)]\n",
    "    \n",
    "df = df_merge_art.copy(deep=True)\n",
    "def sgn(x):\n",
    "    if x == 0: return 0\n",
    "    else: return x/abs(x)\n",
    "# Removes left/right skew \n",
    "for col in ['weekday_fl', 'con_len', 'text_len', 'time_since_first', \n",
    "            'score', 'contr', 'header_len', 'con_num_words', 'text_num_words']:\n",
    "    #min_val = df_merge_art[col].min()\n",
    "    df[col + '_trans'] = df_merge_art[col].apply(lambda x: sgn(x)*math.log(abs(x) + 1))\n",
    "    #show_hist(col + '_trans')\n",
    "\n",
    "# Memory optimization\n",
    "# Technical stuff, contributes nothing to analysis\n",
    "conv = df.select_dtypes(include=['int']).apply(pd.to_numeric,downcast='unsigned')\n",
    "df[conv.columns] = conv\n",
    "    \n",
    "# I removed very weak correlations to \"score\" and \"contr\"\n",
    "cols = ['score', 'score_trans', 'vup', 'vdo', 'weekday', 'hour', 'weekday_fl',\n",
    "       'con_len_trans', 'text_len_trans', 'con_num_words_trans', \n",
    "        'text_num_words_trans',\n",
    "       'time_since_first_trans', 'header_len_trans', \n",
    "        'cat_schweiz', 'cat_finance', 'cat_sport', 'cat_wissen', 'cat_ausland']\n",
    "# Get pearson co-efficients\n",
    "df[cols].corr()\n",
    "\n",
    "#for c in cols:\n",
    "#    print(c)\n",
    "#    print(df[np.isnan(df[col])].head(3))\n",
    "\n",
    "# TODO transform data for learners (non-linear probably)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare and split for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253923\n"
     ]
    }
   ],
   "source": [
    "# https://de.wikipedia.org/wiki/Liste_der_h%C3%A4ufigsten_W%C3%B6rter_der_deutschen_Sprache\n",
    "stop_words = \"die, der, und, in, zu, den, das, nicht, von, sie, ist, des, sich, mit, dem, dass, er, es, ein, ich, auf, so, eine, auch, als, an, nach, wie, im, für\"\n",
    "#stop_words += \"man, aber, aus, durch, wenn, nur, war, noch, werden, bei, hat, wir, was, wird, sein, einen, welche, sind, oder, zur, um, haben, einer, mir, über, ihm, diese, einem, ihr, uns\"\n",
    "#stop_words += \"da, zum, kann, doch, vor, dieser, mich, ihn, du, hatte, seine, mehr, am, denn, nun, unter, sehr, selbst, schon, hier\"\n",
    "#stop_words += \"bis, habe, ihre, dann, ihnen, seiner, alle, wieder, meine, Zeit, gegen, vom, ganz, einzelnen, wo, muss, ohne, eines, können, sei\"\n",
    "stop_words = stop_words.lower()\n",
    "stop_words = stop_words.split(', ')\n",
    "\n",
    "def classify(val):\n",
    "    if val > 10: return 1\n",
    "    return 0\n",
    "\n",
    "X = df.drop(['score', 'contr', 'vup', 'vdo'], axis=1)\n",
    "\n",
    "#y = df_merge_art['score'].apply(classify)\n",
    "y = df['score']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer, PolynomialFeatures\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline, Pipeline, FeatureUnion\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "#from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Select a subset of data at a provided key.\n",
    "    key: hashable, required\n",
    "        The key corresponding to the desired value in a mappable.\n",
    "    '''\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        return df[self.key]\n",
    "    \n",
    "no_numbers = lambda x: re.sub(r'(\\d[\\d\\.])+', '', x.lower())\n",
    "model = Pipeline([\n",
    "    ('union', FeatureUnion(\n",
    "        [\n",
    "            ('statistics', Pipeline([\n",
    "                ('selector', ItemSelector(\n",
    "                    key=['weekday', 'hour', 'con_len_trans', \n",
    "                         'time_since_first_trans',\n",
    "                        'cat_schweiz', 'cat_finance', 'cat_sport', 'cat_wissen', 'cat_ausland',\n",
    "                         'cat_panorama', 'cat_community', 'cat_people', 'cat_digital'\n",
    "                        ])),\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('polynomialfeatures', PolynomialFeatures(degree=2)),\n",
    "            ])),\n",
    "\n",
    "            ('words_content', Pipeline([\n",
    "                ('selector', ItemSelector(key='con')),\n",
    "                ('tfidf', TfidfVectorizer(max_df=0.7, preprocessor=no_numbers)),\n",
    "                ('best', TruncatedSVD(n_components=50)),\n",
    "            ])),\n",
    "            \n",
    "            #('words_text', Pipeline([\n",
    "            #    ('selector', ItemSelector(key='tit')),\n",
    "            #    ('tfidf', TfidfVectorizer(preprocessor=no_numbers)),\n",
    "            #    ('best', TruncatedSVD(n_components=5)),\n",
    "            #])),\n",
    "        ]\n",
    "    )),    \n",
    "    #('model', MLPRegressor(max_iter=50, hidden_layer_sizes=(100,)))\n",
    "    ('model', GradientBoostingRegressor(max_depth=3))\n",
    "    #('model', SVC(kernel='linear', n_jobs=-1))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"R^2: %1.3f\" % r2_score(y_test, y_pred))\n",
    "print(\"Explained var: {:3f}\".format(explained_variance_score(y_test, y_pred)))\n",
    "#print(\"Mean squared error: %1.3f\" % mean_squared_error(y_test, y_pred))\n",
    "print(y_pred)\n",
    "#print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Residual plot\n",
    "X_res = X_test['time_since_first_trans']\n",
    "plt.scatter(X_res, y_test, color='black')\n",
    "plt.scatter(X_res, y_pred, color='red')\n",
    "plt.xlabel('time_since_first_trans')\n",
    "plt.show()\n",
    "\n",
    "if False:\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    param_grid = {\n",
    "        'model__hidden_layer_sizes':[(50,), (100,), (200,), (100, 50)]\n",
    "#        'motdel__alpha': np.logspace(-1, 4, 6),\n",
    "                 }\n",
    "    grid = GridSearchCV(model, param_grid, cv=3)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary so far\n",
    "The decision tree regressor depends a lot on max_depth parameter: Depending on it, the model over- or underfits. I reached the best R^2 score with max_depth=3, but model underfits.\n",
    "\n",
    "Neural networks work a bit better: R^2 = 0.12  \n",
    "GBRF same: R^2 = 0.12\n",
    "\n",
    "How to extract more information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAENCAYAAAAorJMrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f1dcc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 250000 entries, 174315 to 267053\n",
      "Data columns (total 18 columns):\n",
      "tId                 250000 non-null int64\n",
      "cId                 250000 non-null object\n",
      "mob                 250000 non-null int64\n",
      "vup                 250000 non-null int64\n",
      "vdo                 250000 non-null int64\n",
      "tit                 249994 non-null object\n",
      "aut                 249986 non-null object\n",
      "time                250000 non-null object\n",
      "con                 250000 non-null object\n",
      "time_since_epoch    250000 non-null float64\n",
      "hour                250000 non-null int64\n",
      "weekday             250000 non-null int64\n",
      "weekday_fl          250000 non-null float64\n",
      "is_answer           250000 non-null bool\n",
      "con_len             250000 non-null int64\n",
      "con_num_words       250000 non-null int64\n",
      "score               250000 non-null int64\n",
      "contr               250000 non-null int64\n",
      "dtypes: bool(1), float64(2), int64(10), object(5)\n",
      "memory usage: 34.6+ MB\n"
     ]
    }
   ],
   "source": [
    "X_res = []; y_pred = []; y_act = []\n",
    "#for i, item in df.sample(200).iterrows():\n",
    "#    y_pred.append(model.predict([item]))\n",
    "#    y_act.append(item['score'])\n",
    "#    X_res.append(i)\n",
    "n = 200\n",
    "sample = df.sample(n)\n",
    "y_pred = model.predict(sample)\n",
    "y_act = sample['score']\n",
    "X_res = list(range(0, n))\n",
    "    \n",
    "plt.scatter(X_res, y_act, color='black')\n",
    "plt.scatter(X_res, y_pred, color='red')\n",
    "plt.xlabel('i'); plt.ylabel('score')\n",
    "plt.show()\n",
    "\n",
    "df_com.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
