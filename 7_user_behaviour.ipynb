{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping by user\n",
    "\n",
    "Here I will try to group comments by user/user behaviour and use these groups to determine how well which article came off in each group.\n",
    "\n",
    "Approaches:\n",
    "* Group users by number of comments\n",
    "* Group users by length of comments\n",
    "* Group users by title starting with \"@\" (= is_answer)\n",
    "* Group users by time they are active\n",
    "* Maybe group articles...\n",
    "* Some combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "df_art = pd.read_csv('articles_2017_09.csv').sample(500)\n",
    "df_com = pd.read_csv('comments_2017_09.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tId</th>\n",
       "      <th>article_id</th>\n",
       "      <th>updated</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>link</th>\n",
       "      <th>header</th>\n",
       "      <th>sub</th>\n",
       "      <th>text</th>\n",
       "      <th>cat_ausland</th>\n",
       "      <th>cat_auto</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday</th>\n",
       "      <th>is_answer</th>\n",
       "      <th>con_len</th>\n",
       "      <th>con_num_words</th>\n",
       "      <th>score</th>\n",
       "      <th>activity</th>\n",
       "      <th>art_first_weekday</th>\n",
       "      <th>art_first_hour</th>\n",
       "      <th>time_since_first</th>\n",
       "      <th>num_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17728</th>\n",
       "      <td>10008977</td>\n",
       "      <td>10008977</td>\n",
       "      <td>1.504175e+09</td>\n",
       "      <td>73</td>\n",
       "      <td>/schweiz/news/story/10008977</td>\n",
       "      <td>Tunesier lesen Aeschi nach Töff-Panne auf</td>\n",
       "      <td>Um sich ein Bild von den Schlepperrouten zu ma...</td>\n",
       "      <td>Nur einmal gab die 25-jährige Honda Africa Twi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>90.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>954.0</td>\n",
       "      <td>1172.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tId  article_id       updated  num_comments  \\\n",
       "17728  10008977    10008977  1.504175e+09            73   \n",
       "\n",
       "                               link  \\\n",
       "17728  /schweiz/news/story/10008977   \n",
       "\n",
       "                                          header  \\\n",
       "17728  Tunesier lesen Aeschi nach Töff-Panne auf   \n",
       "\n",
       "                                                     sub  \\\n",
       "17728  Um sich ein Bild von den Schlepperrouten zu ma...   \n",
       "\n",
       "                                                    text  cat_ausland  \\\n",
       "17728  Nur einmal gab die 25-jährige Honda Africa Twi...            0   \n",
       "\n",
       "       cat_auto     ...       weekday  is_answer  con_len  con_num_words  \\\n",
       "17728         0     ...           3.0      False     90.0           13.0   \n",
       "\n",
       "       score  activity  art_first_weekday  art_first_hour  time_since_first  \\\n",
       "17728  954.0    1172.0                3.0            15.0               0.0   \n",
       "\n",
       "       num_authors  \n",
       "17728           70  \n",
       "\n",
       "[1 rows x 62 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dt_obj(time):\n",
    "    time = time.replace('am ', '')\n",
    "    # Make datetime object from string\n",
    "    return datetime.strptime(time, '%d.%m.%Y %H:%M')\n",
    "\n",
    "def time_since_epoch(time):\n",
    "    return ((time)-datetime(1970,1,1)).total_seconds()\n",
    "\n",
    "def get_hour_of_day(time):\n",
    "    return (time).hour\n",
    "\n",
    "def get_weekday(time):\n",
    "    return (time).weekday()\n",
    "\n",
    "df_com['time_dt'] = df_com['time'].apply(get_dt_obj)\n",
    "df_com['time_since_epoch'] = df_com['time_dt'].apply(time_since_epoch)\n",
    "df_com['hour'] = df_com['time_dt'].apply(get_hour_of_day)\n",
    "df_com['weekday'] = df_com['time_dt'].apply(get_weekday) # 0 = Monday\n",
    "df_com['is_answer'] = df_com['tit'].apply(lambda x: str(x).startswith('@'))\n",
    "df_com['con_len'] = df_com['con'].apply(len)\n",
    "df_com['con_num_words'] = df_com['con'].apply(lambda x: len(x.split()))\n",
    "df_com['score'] = df_com['vup'] - df_com['vdo']\n",
    "df_com['activity'] = df_com['vup'] + df_com['vdo']\n",
    "#df_com['tit'] = df_com['tit'].str.lower()\n",
    "#df_com['con'] = df_com['con'].str.lower()\n",
    "\n",
    "def get_category(link):\n",
    "    t = link.split('/')\n",
    "    if len(t) <= 1:\n",
    "        return ''\n",
    "    else:\n",
    "        return t[1]\n",
    "\n",
    "df_art['cat'] = df_art['link'].apply(get_category)\n",
    "#df_art['cat_copy'] = df_art['cat']\n",
    "df_art = pd.get_dummies(df_art, columns=['cat'])\n",
    "\n",
    "#df_art['header'] = df_art['header'].str.lower()\n",
    "#df_art['sub'] = df_art['sub'].str.lower()\n",
    "#df_art['text'] = df_art['text'].str.lower()\n",
    "df_art['header_len'] = df_art['header'].apply(len)\n",
    "df_art['sub_len'] = df_art['sub'].apply(lambda x: len(str(x)))\n",
    "df_art['text_len'] = df_art['text'].apply(lambda x: len(str(x)))\n",
    "df_art['text_num_words'] = df_art['text'].apply(lambda x: len(str(x).split()))\n",
    "df_art['text_n_periods'] = df_art['text'].apply(lambda x: len(str(x).split('.')))\n",
    "\n",
    "# Left inner join\n",
    "df_merge = df_art.merge(df_com, left_on='tId', right_on='tId', how='left')\n",
    "\n",
    "# Remove rows with missing values\n",
    "# use .count() to check for missing values\n",
    "df_merge.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "# Get order of comments per article\n",
    "df_merge = df_merge.sort_values(['tId', 'time_since_epoch']).groupby('tId')\n",
    "\n",
    "# Get article specific statistics, group = article\n",
    "# This function is very slow - do on numpy level (sort instead of group)?\n",
    "def get_art_statistics(group):\n",
    "    first = group.iloc[:1]['time_since_epoch']\n",
    "    group['art_first_weekday'] = group.iloc[:1]['weekday']\n",
    "    group['art_first_hour'] = group.iloc[:1]['hour']\n",
    "\n",
    "    group['time_since_first'] = group['time_since_epoch'].apply(lambda x: (x - first) / 3600)\n",
    "    group['num_authors'] = group['aut'].nunique()\n",
    "    return group\n",
    "\n",
    "df_merge = df_merge.apply(get_art_statistics)\n",
    "#df_merge = df_merge.groupby('tId').mean().reset_index()\n",
    "#df_merge = df_merge.merge(df_art[['tId', 'header', 'sub', 'text']], on='tId')\n",
    "\n",
    "df_users = df_com.groupby('aut').mean()\n",
    "df_users.head(1)\n",
    "\n",
    "#df_merge.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions\n",
    "* User dataframe: how many comments on how many articles, how long per comment, when active during the week, is answer\n",
    "* How to define user activity time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aut</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>306498</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217040</th>\n",
       "      <td>I.  P.</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86286</th>\n",
       "      <td>Ghk</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272890</th>\n",
       "      <td>Alain Zürcher</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84997</th>\n",
       "      <td>Ani</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194726</th>\n",
       "      <td>B. Depé</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195670</th>\n",
       "      <td>Barbara</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131694</th>\n",
       "      <td>Barbara</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82951</th>\n",
       "      <td>Bera Terin</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20774</th>\n",
       "      <td>Besen Hexe</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    aut  weekday  hour\n",
       "306498                         1    18\n",
       "217040           I.  P.        1    23\n",
       "86286               Ghk        0    13\n",
       "272890   Alain Zürcher         2     6\n",
       "84997               Ani        2    12\n",
       "194726          B. Depé        0     7\n",
       "195670          Barbara        3     5\n",
       "131694         Barbara         3    11\n",
       "82951       Bera Terin         0     1\n",
       "20774        Besen Hexe        0     7"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aut_weekdays = df_com.groupby('aut')['weekday'].apply(list)\n",
    "#aut_hours = df_com.groupby('aut')['hour'].apply(list)\n",
    "#df_users_wdh = pd.merge(pd.DataFrame(aut_weekdays).reset_index(), pd.DataFrame(aut_hours).reset_index())\n",
    "#df_users_wdh['num_comments'] = df_users_wdh['hour'].apply(len)\n",
    "df_users_wdh = df_com.sort_values('aut')[['aut', 'weekday', 'hour']]\n",
    "df_users_wdh.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Barbara'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-9b0ee6386c61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnbrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_users_wdh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weekday'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hour'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnbrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_users_wdh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_users_wdh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aut'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Barbara'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mquery_is_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mquery_is_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Barbara'"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nbrs = NearestNeighbors(n_jobs=-1).fit(df_users_wdh[['weekday', 'hour']])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
